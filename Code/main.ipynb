{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2432e004",
   "metadata": {},
   "source": [
    "# üê±üß¨ sgRNA Efficiency Prediction with CatBoost\n",
    "\n",
    "This script evaluates **sgRNA efficiency scores** using **CatBoostRegressor** with **5-fold cross-validation**.  \n",
    "It includes **feature importance analysis** and **sequence logos** for nucleotide contribution visualization.  \n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Requirements\n",
    "```bash\n",
    "pip install catboost seaborn logomaker scipy scikit-learn matplotlib pandas numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f455252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logomaker\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "# ============================\n",
    "# Data Loading and Preprocessing\n",
    "# ============================\n",
    "\n",
    "# Read the csv file\n",
    "# 'HL60' - 'Hct116' - 'HeLa'     \"Sniper\" - \"SpCas\" - \"xCas\"     \"WT\" - \"HF\" - \"ESP\"\n",
    "df = pd.read_csv(\"..\\\\Data\\\\HL60Ôºàn=2076Ôºâ.csv\")\n",
    "\n",
    "# Extract sequences and labels\n",
    "sgRNA_seqs = df['sgRNA']\n",
    "y = df['indel'].values.flatten()\n",
    "\n",
    "# One-hot encoding for sequences\n",
    "base_dict = {'A': 0, 'T': 1, 'C': 2, 'G': 3}\n",
    "\n",
    "\n",
    "def base_to_onehot_flat(seq):\n",
    "    \"\"\"Flattened one-hot encoding for compatibility with CatBoost.\"\"\"\n",
    "    arr = np.zeros((len(seq) * 4), dtype=int)\n",
    "    for i, base in enumerate(seq.upper()):\n",
    "        if base in base_dict:\n",
    "            arr[i * 4 + base_dict[base]] = 1\n",
    "    return arr\n",
    "\n",
    "\n",
    "X = np.array([base_to_onehot_flat(seq) for seq in sgRNA_seqs])\n",
    "\n",
    "# ============================\n",
    "# Evaluation Function\n",
    "# ============================\n",
    "\n",
    "\n",
    "def evaluate_catboost_5fold(\n",
    "    X, y,\n",
    "    iterations=500, depth=10, learning_rate=0.01,\n",
    "    l2_leaf_reg=3, border_count=64,\n",
    "    categorical_features=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Train and evaluate CatBoost on sgRNA data using 5-fold cross-validation.\n",
    "    Includes feature importance and nucleotide sequence logo.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=98)\n",
    "    spearman_scores = []\n",
    "    pearson_scores = []\n",
    "\n",
    "    all_feature_importances = np.zeros(X.shape[1])\n",
    "    seq_length = X.shape[1] // 4\n",
    "    all_nucleotide_importances = np.zeros((seq_length, 4))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X), 1):\n",
    "        print(f\"\\n--- Fold {fold} ---\")\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Define and train CatBoost regressor\n",
    "        model = CatBoostRegressor(\n",
    "            iterations=iterations,\n",
    "            depth=depth,\n",
    "            learning_rate=learning_rate,\n",
    "            l2_leaf_reg=l2_leaf_reg,\n",
    "            border_count=border_count,\n",
    "            loss_function='RMSE',\n",
    "            cat_features=categorical_features,\n",
    "            verbose=False\n",
    "        )\n",
    "        model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=0)\n",
    "\n",
    "        # Feature importances\n",
    "        feature_importances = model.get_feature_importance()\n",
    "        all_feature_importances += feature_importances\n",
    "\n",
    "        # Nucleotide importances per position\n",
    "        for pos in range(seq_length):\n",
    "            pos_importances = feature_importances[pos * 4:(pos + 1) * 4]\n",
    "            all_nucleotide_importances[pos] += pos_importances\n",
    "\n",
    "        # Approximate number of parameters\n",
    "        num_params = model.tree_count_ * depth * 2\n",
    "        print(f\"Number of Parameters (estimated): {num_params}\")\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Correlations\n",
    "        spearman_corr, _ = spearmanr(y_test, y_pred)\n",
    "        pearson_corr, _ = pearsonr(y_test, y_pred)\n",
    "        spearman_scores.append(spearman_corr)\n",
    "        pearson_scores.append(pearson_corr)\n",
    "\n",
    "        print(f\"Spearman: {spearman_corr:.4f}, Pearson: {pearson_corr:.4f}\")\n",
    "\n",
    "    # ============================\n",
    "    # Results Summary\n",
    "    # ============================\n",
    "\n",
    "    print(\"\\n=== Average Results over 5 folds ===\")\n",
    "    print(\n",
    "        f\"Avg Spearman: {np.mean(spearman_scores):.4f} ¬± {np.std(spearman_scores):.4f}\")\n",
    "    print(\n",
    "        f\"Avg Pearson : {np.mean(pearson_scores):.4f} ¬± {np.std(pearson_scores):.4f}\")\n",
    "\n",
    "    mean_feature_importances = all_feature_importances / 5\n",
    "    mean_nucleotide_importances = all_nucleotide_importances / 5\n",
    "\n",
    "    # ============================\n",
    "    # Plots\n",
    "    # ============================\n",
    "\n",
    "    # Bar plot of feature importances\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(X.shape[1]), mean_feature_importances)\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Mean Importance')\n",
    "    plt.title('Feature Importances (Mean over 5 Folds)')\n",
    "    plt.show()\n",
    "\n",
    "    # Sequence logo for nucleotide importances\n",
    "    df_importances = pd.DataFrame(\n",
    "        mean_nucleotide_importances, columns=[\"A\", \"T\", \"C\", \"G\"])\n",
    "    logo = logomaker.Logo(df_importances)\n",
    "    logo.style_spines(visible=False)\n",
    "    logo.style_xticks(rotation=90)\n",
    "    logo.ax.set_xticks(np.arange(seq_length))\n",
    "    logo.ax.set_xticklabels(np.arange(1, seq_length + 1))\n",
    "    logo.ax.set_title(\"Nucleotide Importances - Sequence Logo\")\n",
    "    plt.show()\n",
    "    \n",
    "print(\"\\n### Default Parameters Evaluation ###\")\n",
    "evaluate_catboost_5fold(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe6b2eb",
   "metadata": {},
   "source": [
    "# sgRNA Efficiency Prediction with CatBoost + Optuna\n",
    "\n",
    "This code  demonstrates how to optimize a **CatBoostRegressor** for predicting sgRNA efficiency scores using **Optuna**.  \n",
    "The optimization metric is a weighted combination of **Spearman** and **Pearson correlations**.\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Requirements\n",
    "```bash\n",
    "pip install catboost optuna scipy scikit-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb94796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Train/test split (80/20) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=98\n",
    ")\n",
    "\n",
    "# --- Optuna objective function ---\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    iterations = trial.suggest_int('iterations', 500, 2000)  # higher floor, more stable\n",
    "    depth = trial.suggest_int('depth', 4, 10)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 0.1)\n",
    "    l2_leaf_reg = trial.suggest_loguniform('l2_leaf_reg', 1e-2, 10)\n",
    "    border_count = trial.suggest_categorical('border_count', [32, 64])\n",
    "\n",
    "    # Define CatBoost model\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=iterations,\n",
    "        depth=depth,\n",
    "        learning_rate=learning_rate,\n",
    "        l2_leaf_reg=l2_leaf_reg,\n",
    "        border_count=border_count,\n",
    "        loss_function='RMSE',\n",
    "        verbose=False,\n",
    "        random_seed=98\n",
    "    )\n",
    "\n",
    "    # Train with early stopping\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=(X_test, y_test),\n",
    "        early_stopping_rounds=80,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate with Spearman + Pearson\n",
    "    spearman_corr, _ = spearmanr(y_test, y_pred)\n",
    "    pearson_corr, _ = pearsonr(y_test, y_pred)\n",
    "\n",
    "    # Weighted objective (tune weights if you want)\n",
    "    return 0.7 * spearman_corr + 0.3 * pearson_corr\n",
    "\n",
    "# --- Run Optuna study ---\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# --- Show best parameters ---\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best objective value:\", study.best_value)\n",
    "\n",
    "# --- Retrain best model on train data ---\n",
    "best_params = study.best_params\n",
    "final_model = CatBoostRegressor(\n",
    "    iterations=best_params['iterations'],\n",
    "    depth=best_params['depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    l2_leaf_reg=best_params['l2_leaf_reg'],\n",
    "    border_count=best_params['border_count'],\n",
    "    loss_function='RMSE',\n",
    "    verbose=False,\n",
    "    random_seed=98\n",
    ")\n",
    "final_model.fit(X_train, y_train, early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "# --- Evaluate final model ---\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "spearman_corr_test, _ = spearmanr(y_test, y_pred_test)\n",
    "pearson_corr_test, _ = pearsonr(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Test Set Spearman: {spearman_corr_test:.4f}\")\n",
    "print(f\"Test Set Pearson: {pearson_corr_test:.4f}\")\n",
    "\n",
    "# --- Optional: visualize study history ---\n",
    "optuna.visualization.plot_optimization_history(study)\n",
    "optuna.visualization.plot_param_importances(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef69a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n### Default Parameters Evaluation ###\")\n",
    "    evaluate_catboost_5fold(X, y)\n",
    "\n",
    "    print(\"\\n### Best Parameters Evaluation ###\")\n",
    "    evaluate_catboost_5fold(\n",
    "        X, y,\n",
    "        iterations=best_params['iterations'],\n",
    "        depth=best_params['depth'],\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        l2_leaf_reg=best_params['l2_leaf_reg'],\n",
    "        border_count=best_params['border_count']\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
